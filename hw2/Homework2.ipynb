{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27483d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib as plt \n",
    "from pylab import * \n",
    "from scipy.optimize import minimize \n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c2396",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "#### Classical simulated annealing. We will use the Schwefel function for D=10 in order to find its global minimum using CSA ð‘“(ð‘¥1,ð‘¥2...ð‘¥ð·)=418.9829xDâˆ’âˆ‘ ð‘¥ð‘–ð·ð‘– (sin(âˆšð‘¥ð‘–))  ð‘¥ð‘– âˆˆ[âˆ’500,500] for ð‘– =1,...,ð·. In which we use the visitation function of a random displacement along each dimension ð‘¥ð‘– =ð‘¥ð‘– +(2âˆ—ð‘ˆð‘…ð‘âˆ’1)Ã—âˆ†, with âˆ†=0.5 for ð‘– =1,...,ð· "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65161c2a",
   "metadata": {},
   "source": [
    "##### a) Fill  in  the  blanks  in  the  provided  simulated  annealing  code.  Use  a  linear  (Tt+1=Tt-Î±)  cooling schedule with Î±=0.5, and initializing TSA=3000K, to perform CSA until the temperature reaches 30K and 10K,  and  record  the  function  values.  How  long  is  your  cooling  schedule?  Check  against  the  debugging outputs. Given the stochastic nature of CSA, it would be best to report at least 3 runs for each lower bound temperature. Do you find better solutions when cooling to the lower temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schwefel(x):\n",
    "    return 418.9829*len(x)-np.sum(x*np.sin(np.sqrt(np.abs(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SA(solution,evaluation,delta,boundary,cooling_schedule):\n",
    "    \"\"\" Simulated Annealing for minimization\n",
    "    solution: np.array. Initial guess of solution\n",
    "    evaluation: func. Function to evaluate solution\n",
    "    delta: float. Magnitude of random displacement\n",
    "    boundary: array of int/float. [lowerbound,upperbound]\n",
    "    cooling_schedule: np.array. An array of tempretures for simulated annealing\n",
    "    \"\"\"\n",
    "    best_solution=solution.copy()\n",
    "    lowest_eval=evaluation(best_solution)\n",
    "    for idx,temp in enumerate(cooling_schedule):\n",
    "        if idx%500==0:\n",
    "            print(\"%d/%d   temp:%f\"%(idx,len(cooling_schedule),temp))\n",
    "        for n in range(len(solution)):\n",
    "            trial=solution.copy()\n",
    "            trial[n]+=delta*(2*np.random.random()-1)\n",
    "            if trial[n]>=boundary[0] and trial[n]<=boundary[1]:\n",
    "                #fill in acceptance criterion\n",
    "                if np.exp(-(evaluation(trial) - evaluation(solution))/temp) > np.random.random():\n",
    "                    solution=trial\n",
    "                    if evaluation(solution)<lowest_eval:\n",
    "                        #update solution here\n",
    "                        best_solution = solution.copy()\n",
    "                        lowest_eval = evaluation(solution)\n",
    "    return {\"solution\":best_solution,\"evaluation\":lowest_eval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff139d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_point = np.random.random(10)\n",
    "#linear cooling schedule with alpha = 0.5 and initial temperature 3000K \n",
    "cooling_schedule=np.arange(3000,10,-0.5)\n",
    "print(f\"The cooling schedule is {len(cooling_schedule)}K for 10k\")\n",
    "SA(starting_point, schwefel, 0.5, [-500,500], cooling_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bcd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooling_schedule=np.arange(3000,30,-0.5)\n",
    "print(f\"The cooling schedule is {len(cooling_schedule)}K for 10k\")\n",
    "SA(starting_point, schwefel, 0.5, [-500,500], cooling_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d68802",
   "metadata": {},
   "source": [
    "##### The cooling schedule was 5980K for 10K and 5940K for 30K. After running the both the temperatures three times, the following results were retrieved. \n",
    "\n",
    "##### 10K: [4175, 4150,4166] = average : 4163\n",
    "##### 30K: [4129, 4052,4156] = average : 4112 \n",
    "\n",
    "##### Both values are very comparable but from average, it seems that the lower temperature yields better evaluation. With additional studies, this might change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d73908",
   "metadata": {},
   "source": [
    "##### b) Choose logarithmic cooling (Tk=TSA/(1+ TSA log(1+k)/3ï³curr), where k is counter for number of cooling cycle) and ï³curr is an adjustable parameter,  with two initial temperature TSA = 3000K and 6000K. Use ï³curr = 1000 and k = 6000. Reconsider questions (a). Do these cooling schedules converge better than linear cooling? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80912dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_cooling_schedule(T, sigma, k):\n",
    "    cooling_schedule = []\n",
    "    for i in range(k):\n",
    "        cooling_schedule.append(T)\n",
    "        T = T/(1+(T*np.log(1+i)/(3*sigma)))\n",
    "    return cooling_schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA(starting_point, schwefel, 0.5, [-500,500], log_cooling_schedule(3000, 1000, 6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aff2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA(starting_point, schwefel, 0.5, [-500,500], log_cooling_schedule(6000, 1000, 6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa34af4",
   "metadata": {},
   "source": [
    "##### The following averages were calcualted for both the starting temperatures and their evaluations \n",
    "\n",
    "##### 3000K = [4110, 4130, 4110] = 4116 \n",
    "##### 6000K = [4110, 4130, 4089] = 4109 \n",
    "\n",
    "##### The results for logarithmic calculations seemed to be doing better overall when compared to linear cooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb4bab",
   "metadata": {},
   "source": [
    "##### c) Create  your  own  annealing  schedule  (cooling  and  heating  cycles)  to  see  if  you  can  find  better solutions. Use a local optimization technique on your CSA answer, can you find even better solution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule=np.append(cooling_schedule,np.linspace(cooling_schedule[-1],100,200))\n",
    "schedule=np.append(schedule,np.linspace(schedule[-1],1000,2000))\n",
    "schedule=np.append(schedule,np.linspace(schedule[-1],500,100))\n",
    "schedule=np.append(schedule,np.linspace(schedule[-1],5000,3000))\n",
    "schedule=np.append(schedule,np.linspace(schedule[-1],400,100))\n",
    "schedule=np.append(schedule,np.linspace(schedule[-1],4000,3000))\n",
    "schedule=np.append(schedule,np.linspace(schedule[-1],900,100))\n",
    "schedule=np.append(schedule,np.linspace(schedule[-1],9000,2000))\n",
    "plt.figure()\n",
    "plt.plot(schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd999b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CG methods \n",
    "res = minimize(schwefel, starting_point , method='CG', options={'disp':True, 'gtol':1e-5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8522c58",
   "metadata": {},
   "source": [
    "##### The solution is not better than the original solution. Additional analysis of the scenario may lead to better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ead215",
   "metadata": {},
   "source": [
    "## Question 2 \n",
    "\n",
    "### Clustering is a widely used technique in exploratory data analysis that we will examine later using unsupervised learning for classification of objects into groups. But for now we will consider a popular meta-heuristic for solving it using CSA. In this case we would like to cluster N data points into K clusters by solving the minimization of the following cost function:  ð½(ð‘,ð¾)=âˆ‘âˆ‘ð‘¤ð‘–ð‘—ð‘‘ð‘–ð‘—2ð¾ð‘—=1ð‘ð‘–=1    ð‘¤ð‘–ð‘— ={1  ð‘–ð‘“ ð‘ð‘œð‘–ð‘›ð‘¡ ð‘– ð‘–ð‘  ð‘Žð‘ ð‘ ð‘–ð‘”ð‘›ð‘’ð‘‘ ð‘¡ð‘œ ð‘ð‘™ð‘¢ð‘ ð‘¡ð‘’ð‘Ÿ ð‘—0 ð‘œð‘¡â„Žð‘’ð‘Ÿð‘¤ð‘–ð‘ ð‘’, 1â‰¤ð‘– â‰¤ð‘    ð‘Žð‘›ð‘‘    1â‰¤ð‘— â‰¤ð¾  where ð‘‘ð‘–ð‘— is the Euclidean distance between point ð‘– and the center of cluster ð‘—, and condition on ð‘¤ð‘–ð‘— ensures that a point is defined to be in one of the distinct clusters ð¾.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b671f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wines.csv')\n",
    "rank = df['ranking'].tolist()\n",
    "df.drop('ranking', axis=1, inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2e358",
   "metadata": {},
   "source": [
    "##### a) Normalize your chemical descriptor data for each attribute by subtracting off the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of each column \n",
    "mean = df.mean(axis=0)\n",
    "# calculate the standard deviation of each column\n",
    "std = df.std(axis=0)\n",
    "# subtract the mean and divide by the standard deviation\n",
    "df_mean = (df - mean) / std\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57136a2c",
   "metadata": {},
   "source": [
    "##### b) Given the initial categorization of the 178 wines into the 3 clusters according to Start assignment column in the dataset, determine the centroid of each of the three clusters. The centroid for this problem is a 13-D vector where each entry is the mean of a variable for the observations in that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = df_mean.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441587f",
   "metadata": {},
   "source": [
    "##### c) Given the centroid, determine the value of the cost function for this initial categorization. Check against the debugging output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32aad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(centers, feats, ranks):\n",
    "    \"\"\" Cost function for clustering\n",
    "    centers: np.array shape (3,13). Fixed centers\n",
    "    feats: pd.DataFrame. Normalized chemical descriptors\n",
    "    ranks: np.array shape(178,). Assignment.\n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    for i in range(len(ranks)):\n",
    "        cost += LA.norm(feats.iloc[i] - centers[int(ranks[i])]) ** 2\n",
    "    return cost\n",
    "\n",
    "cost(center, df_mean, rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e766a0a",
   "metadata": {},
   "source": [
    "##### d) Fill in the blanks in the provided simulated annealing code. Use CSA with a visitation function in which a randomly chosen wine ð‘– is moved from its present cluster ð‘— to another randomly chosen cluster ð‘˜ â‰ ð‘—. One epoch corresponds to attempting to move all ð‘ wines between clusters, i.e. there are ð‘ Metropolis steps, at each temperature. Use a start temperature of 500, and use a geometric cooling schedule(Tt+1=Î±Tt)  with  Î±=0.999  and  total  of  5000  steps,  again  using  at  least  3  runs  of  CSA.  Check  your  final  temperature against  debugging  output.  Report  all  3  solutions  and  the  wine  members  as  part  of  each  cluster.  Validate your result using the provided code. How well is the assignment?\n",
    "\n",
    "##### I was not able to complete this question as my computer is really slow and was not able to analyze this data. I tried running it for a long amount of time but it did not yield any result beyond the first output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86879d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(feats,ranks,centers,start_temp,alpha,steps=10000):\n",
    "    \"\"\" Simulated Annealing for clustering\n",
    "    feats: pd.DataFrame. Normalized chemical descriptors\n",
    "    ranks: np.array shape(178,). Initial assignment.\n",
    "    centers: np.array shape (3,13). Fixed centers\n",
    "    start_temp: float. Initial tempreture\n",
    "    alpha: float. Hyperparameter for geometric cooling\n",
    "    steps: int. \n",
    "    \"\"\"\n",
    "    best_rank=ranks.copy()\n",
    "    # evaluate the cost function with current best rank\n",
    "    lowest_eval=cost(centers,feats,best_rank)\n",
    "    for step in (range(steps)):\n",
    "        # update tempture according to geometric cooling schedule\n",
    "        temp=start_temp*alpha**step\n",
    "        if step%500==0:\n",
    "            print(step,temp,lowest_eval)\n",
    "        for n in range(len(ranks)):\n",
    "            trial=ranks.copy()\n",
    "            rand_choice=np.random.randint(3)+1\n",
    "            trial[n]=rand_choice\n",
    "            # Metropolis acceptance criterion\n",
    "            if np.exp(-(cost(centers, feats, trial) - cost(centers, feats, ranks)) / start_temp) > np.random.random():\n",
    "                ranks=trial\n",
    "                # update evaluation\n",
    "                new_eval=cost(centers,feats,ranks)\n",
    "                if new_eval<lowest_eval:\n",
    "                    #update best rank and lowest_eval\n",
    "                    best_rank=ranks.copy()\n",
    "                    lowest_eval=new_eval\n",
    "    return {\"solution\":best_rank,\"evaluation\":lowest_eval}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ce438",
   "metadata": {},
   "source": [
    "##### e) Adapt  your  code  in  2(d).  Now  use  CSA  with  a  visitation  function  in  which  a  randomly  chosen centroid ð‘— is updated as a random walk for each of its 13 components  ð‘¥ð‘– =ð‘¥ð‘– +(2âˆ—ð‘ˆð‘…ð‘âˆ’1)Ã—âˆ†; with âˆ†=0.01 In this case one epoch corresponds to moving all ð¾ =3 cluster centers at each temperature, reassigning all wines to their nearest centroid, and evaluating the new cost function. Check against the debugging output to make sure you are assigning wines correctly. Use a start temperature of 500, and use a geometric cooling schedule with Î±=0.999 and total of 5000 steps, again using at least 3 runs of CSA. Report all 3 solutions and the wine members as part of each cluster. Is this a better solution than found in (d)?  \n",
    " \n",
    "\n",
    "##### I was not able to complete this question as my computer is really slow and was not able to analyze this data. I tried running it for a long amount of time but it did not yield any result beyond the first output. See above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_b(feats,ranks,centers,start_temp,alpha,steps=10000):\n",
    "    \"\"\" Simulated Annealing for clustering\n",
    "    feats: pd.DataFrame. Normalized chemical descriptors\n",
    "    ranks: np.array shape(178,). Initial assignment.\n",
    "    centers: np.array shape (3,13). Fixed centers\n",
    "    start_temp: float. Initial tempreture\n",
    "    alpha: float. Hyperparameter for geometric cooling\n",
    "    steps: int. \n",
    "    \"\"\"\n",
    "    best_rank=ranks.copy()\n",
    "    # evaluate the cost function with current best rank\n",
    "    lowest_eval=cost(centers,feats,best_rank)\n",
    "    for step in (range(steps)):\n",
    "        # update tempture according to geometric cooling schedule\n",
    "        temp=start_temp*alpha**step\n",
    "        if step%500==0:\n",
    "            print(step,temp,lowest_eval)\n",
    "        for n in range(len(ranks)):\n",
    "            trial=ranks.copy()\n",
    "            rand_choice=np.random.randint(3)+1\n",
    "            trial[n]+= (2 * rand_choice - 1) * delta\n",
    "            # Metropolis acceptance criterion\n",
    "            if np.exp(-(cost(centers, feats, trial) - cost(centers, feats, ranks)) / start_temp) > np.random.random():\n",
    "                ranks=trial\n",
    "                # update evaluation\n",
    "                new_eval=cost(centers,feats,ranks)\n",
    "                if new_eval<lowest_eval:\n",
    "                    #update best rank and lowest_eval\n",
    "                    best_rank=ranks.copy()\n",
    "                    lowest_eval=new_eval\n",
    "    return {\"solution\":best_rank,\"evaluation\":lowest_eval}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
